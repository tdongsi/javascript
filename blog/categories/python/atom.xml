<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Archived Blog Posts]]></title>
  <link href="http://tdongsi.github.io/javascript/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/javascript/"/>
  <updated>2021-03-21T05:45:14-07:00</updated>
  <id>http://tdongsi.github.io/javascript/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS: Developing With Amazon S3]]></title>
    <link href="http://tdongsi.github.io/javascript/blog/2016/01/18/aws-developing-with-amazon-s3/"/>
    <updated>2016-01-18T17:13:28-08:00</updated>
    <id>http://tdongsi.github.io/javascript/blog/2016/01/18/aws-developing-with-amazon-s3</id>
    <content type="html"><![CDATA[<p>Amazon Simple Storage Service or S3 is a simple, scalable web services to store and retrieve data.
This post talks about basic concepts of buckets and objects in S3, basic and advanced operations on objects in S3, and standard development considerations when working with S3 using SDK.</p>

<!--more-->


<h3>S3 Buckets and Objects</h3>

<p>Files of any kind such as text, video, photo are stored as objects in S3 <em>buckets</em>.
The bucket name must be globally unique across Amazon S3. It is your responsibility to ensure uniqueness of the bucket name.
A bucket can be <em>versioning-enabled</em>, it will store every version of every object in the bucket.</p>

<p>Each <em>object</em> in S3 is identified by a unique key. The object key is used for upload and retrieval. Alphanumeric characters and <code>!-_.*'/</code> are allowed in a key name.</p>

<p>Bucket naming tips:</p>

<ul>
<li>To ensure uniqueness, you might prefix the bucket name with the name of your organization.</li>
<li>Avoid using a period in the bucket name. Buckets that have a period in the bucket name can cause certificate exception when accessing with HTTPS-based URLs.</li>
</ul>


<p>Object key naming tips:</p>

<ul>
<li>Use prefixes and <code>/</code> (or other delimiters) to logically group your objects. For example, <code>prog/java/arrays.html</code>. There is no hierarchy of objects (e.g., folder) or nested buckets in S3.

<ul>
<li>However, the Amazon S3 console supports the <a href="http://docs.aws.amazon.com/AmazonS3/latest/UG/FolderOperations.html">folder concept</a> for convenience and usability. Amazon S3 does this by using key name prefixes for objects.</li>
</ul>
</li>
<li>For performance and scalability, consider using hash as the outermost prefix, in addition to other logical grouping prefixes. See &ldquo;Programming Considerations&rdquo; section below.</li>
</ul>


<h3>Operations on Objects</h3>

<p>Basic operations on S3 objects and buckets are:</p>

<ul>
<li>Put: upload or copy object, up to 5 GB. You can use multi-part upload API for larger objects up to 5 TB.</li>
<li>Get: Retrieve a whole object or part of an object.</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ListingKeysHierarchy.html">List Keys</a>: List object keys by prefix and delimiter.</li>
<li>Delete: Delete one or more objects.

<ul>
<li>If versioning is not enabled, an object is permanently deleted by specifying its key.</li>
<li>If versioning is enabled, you delete an object by specifying a key and version ID. You must delete all versions of an object to remove it.</li>
<li>If versioning is enabled and version is not specified, S3 adds a delete marker to current version of the object. Trying to retrieve an object with a delete marker will returns a &ldquo;404 Not Found&rdquo; error by S3.</li>
</ul>
</li>
<li>Restore: Restore an object archived on Amazon Glacier.</li>
</ul>


<h4>Other operations in S3</h4>

<p>Advanced operations that you should know when situations arise.</p>

<p><strong>Scenario 1</strong>: You want to let users upload files to your buckets for some time duration.
<strong>Solution 1</strong>: You should never share your AWS credentials to let users upload files to your buckets.
Instead, generate a <strong>pre-signed URL</strong> with your security credentials, bucket name, object key, HTTP method (PUT or GET), and expiration date and time.
You share this pre-signed URL to users who will use this to access your S3 buckets.</p>

<p><strong>Scenario 2</strong>: Encryption and strict data security is required.
<strong>Solution 2</strong>: You can enable:</p>

<ul>
<li>Securing data in transit.

<ul>
<li>SSL-encrypted data transfer by using HTTPS</li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html">Client-side encryption</a></li>
</ul>
</li>
<li>Securing data at rest on AWS server.

<ul>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">Server-side encryption</a></li>
</ul>
</li>
</ul>


<p><strong>Scenario 3</strong>: You want your web applications that are loaded in one domain to interact with S3 resources in a different domain.
<strong>Solution 3</strong>: Check out <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html">CORS</a>.</p>

<h3>Programming considerations</h3>

<ul>
<li>According to <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html">this guideline</a>, <strong>avoid</strong> using some sequential prefix (e.g., timestamp or alphabetical sequence) for your objects' key names. Instead, prefix the key name with its hash and, optionally, store the original key name in the object&rsquo;s metadata. See examples in the link for more information.</li>
<li>If your application uses fixed buckets, avoid unnecessary requests by checking the existence of buckets. Instead, handle <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html">NoSuchBucket errors</a> when buckets do not exist.</li>
<li>Set the object metadata before uploading an object. Otherwise, you will have extra requests to do copy operation to update metadata.</li>
<li>Cache bucket and key names if possible.</li>
<li>Set bucket region closest to latency-sensitive users.</li>
<li>Compress objects to reduce the size of data transferred and storage used.</li>
<li>Use an exponential back-off algorithm to retry after failed connection attempts. See <a href="http://docs.aws.amazon.com/general/latest/gr/api-retries.html">here</a>.</li>
<li>Enable application logging. For example, <a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/java-dg-logging.html">in Java</a>.</li>
<li>Enable <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html">server access logging</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: Getting Started on Mac OSX]]></title>
    <link href="http://tdongsi.github.io/javascript/blog/2016/01/17/aws-set-up-aws-credentials-on-mac-osx/"/>
    <updated>2016-01-17T20:57:35-08:00</updated>
    <id>http://tdongsi.github.io/javascript/blog/2016/01/17/aws-set-up-aws-credentials-on-mac-osx</id>
    <content type="html"><![CDATA[<p>Quick-start guide on AWS development in Java and Python.</p>

<!--more-->


<h3>Set up AWS development environment</h3>

<p>First, you need to set up your AWS credentials on your Mac by creating the following files at the following specific locations:</p>

<pre><code class="plain">MTVL1288aeea2-82:~ cdongsi$ mkdir ~/.aws
MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/credentials
MTVL1288aeea2-82:~ cdongsi$ touch ~/.aws/config
</code></pre>

<p>In Windows, the locations of those files will be <code>C:\Users\USERNAME\.aws\credentials</code> and <code>C:\Users\USERNAME\.aws\config</code>, respectively.
You <em>must</em> fill in your AWS access credentials (Access Key ID and Secret Access Key) into the file <code>credentials</code>. Optionally, you can set the default region in the <code>config</code> file.
The content of the files will look like the following:</p>

<pre><code class="plain">MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/credentials
[default]
aws_access_key_id = your_access_key_id
aws_secret_access_key = your_secret_access_key

MTVL1288aeea2-82:~ cdongsi$ cat ~/.aws/config
[default]
region=us-west-2
</code></pre>

<h3>HelloAws using Java</h3>

<p>Now, you can install AWS Toolkit for Eclipse from <a href="http://aws.amazon.com/eclipse/">this link</a>. Follow the instruction in that page to install AWS Toolkit.</p>

<p>After AWS Toolkit is installed, you are ready to run the first <code>HelloAws</code> Java application. In Eclipse, create a AWS Console application.</p>

<ol>
<li>Click the new orange button on Eclipse taskbar named &ldquo;AWS Toolkit for Eclipse&rdquo;.</li>
<li>Click the link named &ldquo;Create a New AWS Java Project&rdquo;.</li>
<li>Fill in &ldquo;Project name&rdquo; as &ldquo;HelloAws&rdquo;. Check &ldquo;AWS Console Application&rdquo; from &ldquo;AWS SDK for Java Samples&rdquo; panel.</li>
</ol>


<p>Note that the sample generated has the following instruction in its main class. If you haven&rsquo;t do it, follow the steps above to set up your AWS access credentials.</p>

<pre><code class="java">public class AwsConsoleApp {

    /*
     * Before running the code:
     *      Fill in your AWS access credentials in the provided credentials
     *      file template, and be sure to move the file to the default location
     *      (/Users/cdongsi/.aws/credentials) where the sample code will load the
     *      credentials from.
     *      https://console.aws.amazon.com/iam/home?#security_credential
     *
     * WARNING:
     *      To avoid accidental leakage of your credentials, DO NOT keep
     *      the credentials file in your source directory.
     */

    static AmazonEC2      ec2;
    static AmazonS3       s3;
    static AmazonSimpleDB sdb;
</code></pre>

<p>If your AWS credentials are ready, simply run the sample AWS console code as &ldquo;Java Application&rdquo;. The output will look something like this:</p>

<pre><code class="plain">===========================================
Welcome to the AWS Java SDK!
===========================================
You have access to 4 Availability Zones.
You have 0 Amazon EC2 instance(s) running.
You have 0 Amazon SimpleDB domain(s)containing a total of 0 items.
You have 0 Amazon S3 bucket(s), containing 0 objects with a total size of 0 bytes.
</code></pre>

<h3>HelloAws using Python</h3>

<p>To install <a href="http://aws.amazon.com/sdk-for-python/">AWS SDK for Python</a>, run the following the command as instructed in that page:</p>

<pre><code>pip install boto3
</code></pre>

<p>In my case, I used a slightly different command to avoid permission errors on Mac OSX:</p>

<pre><code>pip install boto3 --user
</code></pre>

<p>I use PyCharm/IntelliJ as IDE for Python and, apparently, there is no Python sample for it. In PyCharm, you can use the following Python script as your <code>HelloAws</code> program:</p>

<pre><code class="python">import boto3
from botocore.exceptions import ClientError,NoCredentialsError
import sys

def getS3BucketNumber():

    try:
        s3 = boto3.resource('s3')
        buckets = []
    except NoCredentialsError:
        print "No AWS Credentials"
        sys.exit()

    try:
        bucket_num = len(list(s3.buckets.all()))
        print "Number of buckets: " + str(bucket_num)
        return bucket_num
    except ClientError as ex:
        print(ex)
        return 0

if __name__ == '__main__':
    getS3BucketNumber()
</code></pre>

<p>Note that it is based on the <a href="https://github.com/boto/boto3#quick-start">Quick start on Github</a>. In PyCharm, running the above Python should print the following output:</p>

<pre><code class="plain">Number of buckets: 0
</code></pre>

<h3>Quick note on Python API vs. Java API</h3>

<p>Note that Boto3 SDK for Python support <a href="http://boto3.readthedocs.org/en/latest/guide/resources.html">&ldquo;Resource API&rdquo;</a>.
As opposed to &ldquo;Service Client API&rdquo; like AWS SDK for Java, Resource API provides a higher level interface to the service and it is easier to understand and simpler to use.</p>

<p>For example, the generated example for AWS&rsquo;s Java SDK uses a Service Client API. It uses a class AmazonS3Client that controls the requests you make to the S3 service.
Meanwhile, the Boto3 SDK for Python has classes representing the conceptual resources (e.g., s3.Bucket) that you interact with when using the S3 service.
This is a higher level abstraction compared to a client class like AmazonS3Client making low-level calls to the service API.</p>

<h3>External Links</h3>

<ul>
<li>Python

<ul>
<li><a href="https://boto3.readthedocs.org/en/latest/guide/index.html">Developer Guide</a></li>
<li><a href="https://boto3.readthedocs.org/en/latest/reference/core/index.html">API Documentation</a></li>
</ul>
</li>
<li>Java

<ul>
<li><a href="http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/welcome.html">Developer Guide</a></li>
<li><a href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html">API Documentation</a></li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
